{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'atoti'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ab6f049b0653>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0matoti\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0matoti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'atoti'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting atoti\n",
      "  Using cached atoti-0.5.2-0_6b58d72-py3-none-any.whl (141.4 MB)\n",
      "Requirement already satisfied: numpy!=1.19.4 in c:\\users\\alimi\\anaconda3\\lib\\site-packages (from atoti) (1.19.2)\n",
      "Collecting typeguard\n",
      "  Downloading typeguard-2.11.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\alimi\\anaconda3\\lib\\site-packages (from atoti) (3.7.4.3)\n",
      "Collecting jdk4py==11.0.9.0\n",
      "  Downloading jdk4py-11.0.9.0-py3-none-win_amd64.whl (34.1 MB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\alimi\\anaconda3\\lib\\site-packages (from atoti) (5.3.1)\n",
      "Collecting pyarrow>=2.0.0\n",
      "  Downloading pyarrow-3.0.0-cp38-cp38-win_amd64.whl (12.7 MB)\n",
      "Requirement already satisfied: pandas in c:\\users\\alimi\\anaconda3\\lib\\site-packages (from atoti) (1.1.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\alimi\\anaconda3\\lib\\site-packages (from pandas->atoti) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\alimi\\anaconda3\\lib\\site-packages (from pandas->atoti) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alimi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->atoti) (1.15.0)\n",
      "Installing collected packages: typeguard, jdk4py, pyarrow, atoti\n",
      "Successfully installed atoti-0.5.2 jdk4py-11.0.9.0 pyarrow-3.0.0 typeguard-2.11.1\n"
     ]
    }
   ],
   "source": [
    "import atoti as tt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from atoti.config import create_config\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import acf, grangercausalitytests, pacf\n",
    "from util import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = [\n",
    "    \"BTC\",\n",
    "    \"ETH\",\n",
    "    \"USDT\",\n",
    "    \"XRP\",\n",
    "    \"BCH\",\n",
    "    \"ADA\",\n",
    "    \"BSV\",\n",
    "    \"LTC\",\n",
    "    \"LINK\",\n",
    "    \"BNB\",\n",
    "    \"EOS\",\n",
    "    \"TRON\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = create_config(metadata_db=\"./metadata.db\")\n",
    "session = tt.create_session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_store = session.read_csv(\n",
    "    \"s3://data.atoti.io/notebooks/twitter/crypto_prices.csv\",\n",
    "    #     \"prices.csv\",\n",
    "    keys=[\"coin_symbol\", \"date\"],\n",
    "    store_name=\"currency price\",\n",
    ")\n",
    "price_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"https://data.atoti.io/notebooks/twitter/tweets_metrics.csv\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"Subset\"] = \"Train\"\n",
    "tweets.loc[tweets.groupby([\"coin_symbol\"])[\"date\"].tail(7).index, \"Subset\"] = \"Test\"\n",
    "tweets.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets_store = session.read_pandas(\n",
    "    tweets,\n",
    "    keys=[\"coin_symbol\", \"date\"],\n",
    "    store_name=\"tweets\",\n",
    "    types={\n",
    "        \"Tweet volume\": tt.type.FLOAT,\n",
    "        \"Retweet total\": tt.type.FLOAT,\n",
    "        \"Retweet average\": tt.type.FLOAT,\n",
    "        \"Followers total\": tt.type.FLOAT,\n",
    "        \"Followers average\": tt.type.FLOAT,\n",
    "        \"Favorite total\": tt.type.FLOAT,\n",
    "        \"Favorite average\": tt.type.FLOAT,\n",
    "        \"Polarity total\": tt.type.FLOAT,\n",
    "        \"Polarity average\": tt.type.FLOAT,\n",
    "        \"Negative\": tt.type.FLOAT,\n",
    "        \"Neutral\": tt.type.FLOAT,\n",
    "        \"Positive\": tt.type.FLOAT,\n",
    "        \"Bullish ratio\": tt.type.FLOAT,\n",
    "        \"Subset\": tt.type.STRING,\n",
    "    },\n",
    ")\n",
    "tweets_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_store.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_store = session.read_csv(\n",
    "    \"s3://data.atoti.io/notebooks/twitter/currency_dict.csv\",\n",
    "    keys=[\"coin_symbol\"],\n",
    "    store_name=\"currency\",\n",
    ")\n",
    "currency_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = session.create_cube(tweets_store, name=\"Cryptocurrency cube\", mode=\"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_store.join(price_store)\n",
    "price_store.join(currency_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = cube.hierarchies\n",
    "l = cube.levels\n",
    "m = cube.measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[\"Coin Symbol\"] = [tweets_store[\"coin_symbol\"], currency_store[\"currency_name\"]]\n",
    "h[\"Coin Symbol\"].dimension = \"Cryptocurrency\"\n",
    "h[\"Coin Symbol\"].slicing = True\n",
    "\n",
    "h[\"Date\"] = [tweets_store[\"date\"]]\n",
    "h[\"Date\"].dimension = \"Time-series\"\n",
    "\n",
    "# used for splitting training and test data\n",
    "h[\"Subset\"] = [tweets_store[\"Subset\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Multi-level hierarchies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"Tweet volume\"] = tt.agg.sum(tweets_store[\"Tweet volume\"])\n",
    "m[\"Retweet total\"] = tt.agg.sum(tweets_store[\"Retweet total\"])\n",
    "m[\"Followers total\"] = tt.agg.sum(tweets_store[\"Followers total\"])\n",
    "m[\"Favorite total\"] = tt.agg.sum(tweets_store[\"Favorite total\"])\n",
    "m[\"Polarity total\"] = tt.agg.sum(tweets_store[\"Polarity total\"])\n",
    "m[\"Negative\"] = tt.agg.sum(tweets_store[\"Negative\"])\n",
    "m[\"Neutral\"] = tt.agg.sum(tweets_store[\"Neutral\"])\n",
    "m[\"Positive\"] = tt.agg.sum(tweets_store[\"Positive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"Retweet average\"] = tt.agg.mean(tweets_store[\"Retweet average\"])\n",
    "m[\"Followers average\"] = tt.agg.mean(tweets_store[\"Followers average\"])\n",
    "m[\"Favorite average\"] = tt.agg.mean(tweets_store[\"Favorite average\"])\n",
    "m[\"Polarity average\"] = tt.agg.mean(tweets_store[\"Polarity average\"])\n",
    "\n",
    "m[\"Price\"] = tt.agg.mean(price_store[\"Price\"])\n",
    "m[\"Returns\"] = tt.agg.mean(price_store[\"Returns\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"Bullish ratio\"] = m[\"Positive\"] / m[\"Negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Bullish ratio for BTC and ETH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Tweet volumes for BTC and ETH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_folder = \"metrics\"\n",
    "m[\"Tweet volume\"].folder = metrics_folder\n",
    "m[\"Retweet total\"].folder = metrics_folder\n",
    "m[\"Followers total\"].folder = metrics_folder\n",
    "m[\"Favorite total\"].folder = metrics_folder\n",
    "m[\"Polarity total\"].folder = metrics_folder\n",
    "m[\"Negative\"].folder = metrics_folder\n",
    "m[\"Neutral\"].folder = metrics_folder\n",
    "m[\"Positive\"].folder = metrics_folder\n",
    "m[\"Retweet average\"].folder = metrics_folder\n",
    "m[\"Followers average\"].folder = metrics_folder\n",
    "m[\"Favorite average\"].folder = metrics_folder\n",
    "m[\"Polarity average\"].folder = metrics_folder\n",
    "m[\"Price\"].folder = metrics_folder\n",
    "m[\"Returns\"].folder = metrics_folder\n",
    "m[\"Bullish ratio\"].folder = metrics_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[\"coin_symbol\"].comparator = tt.comparator.first_members(coins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Default slicing member ordering updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = cube.query(\n",
    "    m[\"Price\"],\n",
    "    m[\"Returns\"],\n",
    "    m[\"Tweet volume\"],\n",
    "    m[\"Retweet total\"],\n",
    "    m[\"Retweet average\"],\n",
    "    m[\"Followers total\"],\n",
    "    m[\"Followers average\"],\n",
    "    m[\"Favorite total\"],\n",
    "    m[\"Favorite average\"],\n",
    "    m[\"Polarity total\"],\n",
    "    m[\"Polarity average\"],\n",
    "    m[\"Bullish ratio\"],\n",
    "    levels=[l[\"coin_symbol\"], l[\"date\"]],\n",
    "    condition=(l[\"Subset\"] == \"Train\"),\n",
    ")\n",
    "\n",
    "metrics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProfileReport(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_stats = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"coin_symbol\",\n",
    "        \"metric_name\",\n",
    "        \"norm_stat\",\n",
    "        \"norm_p\",\n",
    "        \"kurtosis\",\n",
    "        \"skewness\",\n",
    "        \"lag_acf\",\n",
    "        \"lag_pacf\",\n",
    "        \"std\",\n",
    "        \"durbin_watson\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.url + \"/#/dashboard/810\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coin in coins:\n",
    "    coin_df = metrics_df.loc[[coin]]\n",
    "    for metric_name in coin_df.columns:\n",
    "        metric = coin_df[metric_name]\n",
    "\n",
    "        # autocorrelation\n",
    "        lag_acf = \";\".join(map(str, acf(metric, nlags=50, fft=True).tolist()))\n",
    "        lag_pacf = \";\".join(map(str, pacf(metric, nlags=50, method=\"ols\").tolist()))\n",
    "\n",
    "        data_stats = data_stats.append(\n",
    "            {\n",
    "                \"coin_symbol\": coin,\n",
    "                \"metric_name\": metric_name,\n",
    "                \"lag_acf\": lag_acf,\n",
    "                \"lag_pacf\": lag_pacf,\n",
    "                \"std\": metric.std(),\n",
    "            },\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "data_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_store = session.read_pandas(\n",
    "    data_stats,\n",
    "    keys=[\"coin_symbol\", \"metric_name\"],\n",
    "    store_name=\"statistics\",\n",
    "    types={\"lag_acf\": tt.type.FLOAT_ARRAY, \"lag_pacf\": tt.type.FLOAT_ARRAY},\n",
    "    array_sep=\";\",\n",
    ")\n",
    "stats_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_store.join(stats_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[\"metric_name\"].dimension = \"Metrics\"\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m[\"lag_acf\"] = tt.agg._single_value(stats_store[\"lag_acf\"])\n",
    "m[\"lag_pacf\"] = tt.agg._single_value(stats_store[\"lag_pacf\"])\n",
    "m[\"std\"] = tt.agg._single_value(stats_store[\"std\"])\n",
    "\n",
    "# placeholder for later test data\n",
    "m[\"norm_stat\"] = tt.agg._single_value(stats_store[\"norm_stat\"])\n",
    "m[\"norm_p\"] = tt.agg._single_value(stats_store[\"norm_p\"])\n",
    "m[\"kurtosis\"] = tt.agg._single_value(stats_store[\"kurtosis\"])\n",
    "m[\"skewness\"] = tt.agg._single_value(stats_store[\"skewness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"durbin watson\"] = tt.agg._stop(\n",
    "    tt.agg._single_value(stats_store[\"durbin_watson\"]), l[\"metric_name\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_folder = \"Statistics\"\n",
    "m[\"std\"].folder = stats_folder\n",
    "m[\"lag_acf\"].folder = stats_folder\n",
    "m[\"lag_pacf\"].folder = stats_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Bit coin metrics statistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.create_static_parameter_hierarchy(\n",
    "    \"Lags\", list(range(0, 50)), index_measure=\"Lag Index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[\"Lags\"].slicing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m[\"acf\"] = m[\"lag_acf\"][m[\"Lag Index\"]]\n",
    "m[\"acf\"].formatter = \"DOUBLE[#,###.0000]\"\n",
    "\n",
    "m[\"pacf\"] = m[\"lag_pacf\"][m[\"Lag Index\"]]\n",
    "m[\"pacf\"].formatter = \"DOUBLE[#,###.0000]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"Sample size\"] = tt.total(tt.agg.count_distinct(tweets_store[\"date\"]), h[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"critical value\"] = 1.96\n",
    "m[\"Upper 95% confidence interval\"] = m[\"critical value\"] / tt.math.sqrt(m[\"Sample size\"])\n",
    "m[\"Lower 95% confidence interval\"] = -m[\"critical value\"] / tt.math.sqrt(m[\"Sample size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Auto-correlation for BTC price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Auto-correlation for BTC Returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_cols = metrics_df.reset_index().columns.to_list()\n",
    "transformed_df = pd.DataFrame(columns=metric_cols).set_index([\"coin_symbol\", \"date\"])\n",
    "\n",
    "metric_cols.append(\"order\")\n",
    "full_diff_df = pd.DataFrame(columns=metric_cols).set_index(\n",
    "    [\"coin_symbol\", \"date\", \"order\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coin in coins:\n",
    "    coin_df = metrics_df.loc[[coin]].dropna()\n",
    "\n",
    "    # reset dataframe\n",
    "    full_diff_df = pd.DataFrame()\n",
    "\n",
    "    for col in coin_df.columns:\n",
    "        full_diff_df, coin_df[col] = utils.augmented_dickey_fuller_statistics(\n",
    "            coin, col, coin_df[col], 0, full_diff_df\n",
    "        )\n",
    "\n",
    "    if len(full_diff_df) > 0:\n",
    "        full_diff_df.reset_index(inplace=True)\n",
    "        for diff_order in full_diff_df[\"order\"].unique():\n",
    "            scenario = full_diff_df.loc[full_diff_df[\"order\"] == diff_order].copy()\n",
    "            scenario.dropna(axis=\"columns\", how=\"all\", inplace=True)\n",
    "            scenario[\"Subset\"] = \"Train\"\n",
    "\n",
    "            price_store.scenarios[f\"d{diff_order}\"].load_pandas(\n",
    "                scenario.loc[\n",
    "                    :, scenario.columns.isin([\"coin_symbol\", \"date\", \"Price\", \"Return\"])\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            tweets_store.scenarios[f\"d{diff_order}\"].load_pandas(\n",
    "                scenario.drop(columns=[\"order\", \"Price\", \"Return\"], errors=\"ignore\")\n",
    "            )\n",
    "\n",
    "    coin_df.dropna(inplace=True)\n",
    "    transformed_df = transformed_df.append(coin_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Non stationary Price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Stationary Returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.url + \"/#/dashboard/010\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grangercausalitytests_df = pd.DataFrame(columns=[\"coin_symbol\", \"x\", \"y\",])\n",
    "\n",
    "\n",
    "def grangers_causality_matrix(coin, train_data, maxlag, verbose=False):\n",
    "    global grangercausalitytests_df\n",
    "    columns = train_data.columns\n",
    "\n",
    "    r = \"Returns\"\n",
    "    scal = StandardScaler()\n",
    "    df_scaled = pd.DataFrame(\n",
    "        scal.fit_transform(train_data.values),\n",
    "        columns=train_data.columns,\n",
    "        index=train_data.index,\n",
    "    )\n",
    "\n",
    "    for c in columns:\n",
    "        if c not in [\"Price\", \"Returns\"]:\n",
    "            if verbose:\n",
    "                print(f\"{coin} ============= Returns against {c}\")\n",
    "\n",
    "            X_train = df_scaled[[r, c]]\n",
    "\n",
    "            gc_test_result = grangercausalitytests(\n",
    "                X_train, maxlag=maxlag, verbose=False\n",
    "            )\n",
    "            if verbose:\n",
    "                print(\"********************************************\")\n",
    "                print(gc_test_result)\n",
    "\n",
    "            # transform test_result into stats for x causes y\n",
    "            grangercausalitytests_df = utils.transform_gc_date(\n",
    "                coin, gc_test_result, c, r, maxlag, grangercausalitytests_df, verbose\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coin in coins:\n",
    "    coin_train_data = transformed_df.loc[\n",
    "        (transformed_df.index.get_level_values(\"coin_symbol\") == coin)\n",
    "    ]\n",
    "\n",
    "    grangers_causality_matrix(coin, coin_train_data.copy(), 50, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grangercausalitytests_df.loc[\n",
    "    (grangercausalitytests_df[\"coin_symbol\"] == \"BTC\")\n",
    "    & (grangercausalitytests_df[\"Test name\"] == \"params_ftest\")\n",
    "].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "granger_causality_store = session.read_pandas(\n",
    "    grangercausalitytests_df,\n",
    "    keys=[\"coin_symbol\", \"Test name\", \"x\", \"y\"],\n",
    "    store_name=\"Granger Causality\",\n",
    "    types={\n",
    "        \"F\": tt.type.FLOAT_ARRAY,\n",
    "        \"chi2\": tt.type.FLOAT_ARRAY,\n",
    "        \"p-value\": tt.type.FLOAT_ARRAY,\n",
    "        \"df\": tt.type.FLOAT_ARRAY,\n",
    "        \"df_denom\": tt.type.FLOAT_ARRAY,\n",
    "        \"df_num\": tt.type.FLOAT_ARRAY,\n",
    "    },\n",
    "    array_sep=\";\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "granger_causality_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_store.join(granger_causality_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[\"Test name\"] = [granger_causality_store[\"Test name\"]]\n",
    "h[\"Test name\"].slicing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"v_F\"] = tt.agg._single_value(granger_causality_store[\"F\"])\n",
    "m[\"v_chi2\"] = tt.agg._single_value(granger_causality_store[\"chi2\"])\n",
    "m[\"v_p_value\"] = tt.agg._single_value(granger_causality_store[\"p-value\"])\n",
    "\n",
    "m[\"v_df\"] = tt.agg._single_value(granger_causality_store[\"df\"])\n",
    "m[\"v_df_denom\"] = tt.agg._single_value(granger_causality_store[\"df_denom\"])\n",
    "m[\"v_df_num\"] = tt.agg._single_value(granger_causality_store[\"df_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level of significance\n",
    "m[\"alpha\"] = 0.05\n",
    "\n",
    "m[\"GCT F\"] = m[\"v_F\"][m[\"Lag Index\"]]\n",
    "m[\"GCT chi2\"] = m[\"v_chi2\"][m[\"Lag Index\"]]\n",
    "m[\"GCT p-value\"] = m[\"v_p_value\"][m[\"Lag Index\"]]\n",
    "m[\"GCT df\"] = m[\"v_df\"][m[\"Lag Index\"]]\n",
    "m[\"GCT df_denom\"] = m[\"v_df_denom\"][m[\"Lag Index\"]]\n",
    "m[\"GCT df_num\"] = m[\"v_df_num\"][m[\"Lag Index\"]]\n",
    "\n",
    "m[\"GCT F\"].formatter = \"DOUBLE[#,###.000000]\"\n",
    "m[\"GCT chi2\"].formatter = \"DOUBLE[#,###.000000]\"\n",
    "m[\"GCT p-value\"].formatter = \"DOUBLE[#,###.000000]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Granger causality test Params_ftest p-value for Bitcoin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"Granger causality\"] = tt.agg.sum(\n",
    "    tt.where(m[\"GCT p-value\"] < m[\"alpha\"], 1, None), scope=tt.scope.origin(l[\"Lags\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Number of lags with null hypothesis rejected for params_ftest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.url + \"/#/dashboard/70f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_store = session.create_store(\n",
    "    store_name=\"residual\",\n",
    "    keys=[\"coin_symbol\", \"date\"],\n",
    "    types={\n",
    "        \"coin_symbol\": tt.type.STRING,\n",
    "        \"date\": tt.type.LOCAL_DATE,\n",
    "        \"Returns residual\": tt.type.FLOAT,\n",
    "    },\n",
    ")\n",
    "residual_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forecast_store = session.create_store(\n",
    "    store_name=\"Forecast accuracy\",\n",
    "    keys=[\"coin_symbol\"],\n",
    "    types={\n",
    "        \"coin_symbol\": tt.type.STRING,\n",
    "        \"lag_order\": tt.type.INT,\n",
    "        \"Observations\": tt.type.INT,\n",
    "        \"mape\": tt.type.FLOAT,\n",
    "        \"me\": tt.type.FLOAT,\n",
    "        \"mae\": tt.type.FLOAT,\n",
    "        \"mpe\": tt.type.FLOAT,\n",
    "        \"rmse\": tt.type.FLOAT,\n",
    "        \"corr\": tt.type.FLOAT,\n",
    "        \"minmax\": tt.type.FLOAT,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_store.join(residual_store)\n",
    "granger_causality_store.join(forecast_store)\n",
    "cube.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m[\"Returns residual\"] = tt.agg._single_value(residual_store[\"Returns residual\"])\n",
    "m[\"Returns residual\"].formatter = \"DOUBLE[#,###.0000]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stats_name = forecast_store.columns\n",
    "stats_name.remove(\"coin_symbol\")\n",
    "stats_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in stats_name:\n",
    "    m[name] = tt.agg._single_value(forecast_store[name])\n",
    "\n",
    "    m[name].folder = \"Statistics\"\n",
    "    m[name].formatter = (\n",
    "        \"DOUBLE[#,###]\"\n",
    "        if name in [\"lag_order\", \"Observations\"]\n",
    "        else \"DOUBLE[#,###.0000]\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_metrics = cube.query(\n",
    "    m[\"Granger causality\"],\n",
    "    levels=[l[\"coin_symbol\"], l[\"x\"]],\n",
    "    condition=l[\"Test name\"] == \"params_ftest\",\n",
    ").reset_index()\n",
    "features_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_forecast(scenario_name, features, data, verbose=False):\n",
    "    global coins\n",
    "    for coin in coins:\n",
    "        # obtain the features that may Granger cause returns\n",
    "        metrics_col = features.loc[features[\"coin_symbol\"] == coin][\"x\"].to_list()\n",
    "        metrics_col = [\"Returns\"] + metrics_col\n",
    "\n",
    "        actual_df = cube.query(\n",
    "            m[\"Returns\"],\n",
    "            levels=[l[\"coin_symbol\"], l[\"date\"]],\n",
    "            condition=(l[\"Subset\"] == \"Test\") & (l[\"coin_symbol\"] == coin),\n",
    "        )\n",
    "\n",
    "        if len(metrics_col) == 1:\n",
    "            print(coin, \"=========== No features Granger cause returns\")\n",
    "            actual_df[\"Returns\"] = np.nan\n",
    "            price_store.scenarios[scenario_name].load_pandas(actual_df)\n",
    "\n",
    "        else:\n",
    "            print(\n",
    "                f\"Forecasting {coin} returns based on features\",\n",
    "                features.loc[features[\"coin_symbol\"] == coin][\"x\"].to_list(),\n",
    "            )\n",
    "\n",
    "            train_data = data.loc[\n",
    "                (transformed_df.index.get_level_values(\"coin_symbol\") == coin)\n",
    "            ][metrics_col]\n",
    "\n",
    "            train_data = train_data.reset_index([\"coin_symbol\"], drop=True)\n",
    "\n",
    "            nobs = 7\n",
    "            df_residual, ds, accuracy_prod, df_forecast = utils.var_forecast(\n",
    "                coin,\n",
    "                data_stats.copy(),\n",
    "                train_data.copy(),\n",
    "                actual_df,\n",
    "                nobs,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "\n",
    "            accuracy_prod.reset_index(inplace=True)\n",
    "            accuracy_prod.rename(columns={\"index\": \"coin_symbol\"}, inplace=True)\n",
    "\n",
    "            if df_forecast is not None:\n",
    "                price_store.scenarios[scenario_name].load_pandas(df_forecast)\n",
    "                residual_store.scenarios[scenario_name].load_pandas(df_residual)\n",
    "                stats_store.scenarios[scenario_name].load_pandas(ds)\n",
    "                forecast_store.scenarios[scenario_name].load_pandas(accuracy_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_forecast(\"forecast (0.05)\", features_metrics, transformed_df, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Cryptocurrency forecast for BTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.url + \"/#/dashboard/010\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[\"Prev day returns\"] = tt.date_shift(\n",
    "    m[\"Returns\"], on=h[\"Date\"], offset=\"-1D\", method=\"exact\"\n",
    ")\n",
    "m[\"Trend\"] = tt.where(\n",
    "    (m[\"Returns\"] - m[\"Prev day returns\"]) < 0,\n",
    "    -1,\n",
    "    tt.where((m[\"Returns\"] - m[\"Prev day returns\"]) > 0, 1, 0),\n",
    ")\n",
    "m[\"Trend Sign\"] = tt.where(\n",
    "    (m[\"Returns\"] - m[\"Prev day returns\"]) < 0,\n",
    "    \"ðŸ“‰\",\n",
    "    tt.where((m[\"Returns\"] - m[\"Prev day returns\"]) > 0, \"ðŸ“ˆ\", \"âž¡\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Trend analysis across forcast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m[\"Gaussian confidence\"] = 0.05\n",
    "m[\"Distribution type\"] = tt.where(\n",
    "    m[\"norm_p\"] != None,\n",
    "    tt.where((m[\"norm_p\"] < m[\"Gaussian confidence\"]), \"Non-Gaussian\", \"Gaussian\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Distribution check for Returns at 95% confidence level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Durbin-watson check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Forecast accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Tweet volume by cryptocurrency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.url + \"/#/dashboard/332\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_simulation = cube.setup_simulation(\n",
    "    \"Significance simulation\", replace=[m[\"alpha\"]], base_scenario=\"0.05\"\n",
    ").scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_simulation[\"0.01\"] = 0.01\n",
    "significant_simulation[\"0.1\"] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_metrics = cube.query(\n",
    "    m[\"Granger causality\"],\n",
    "    levels=[l[\"Significance simulation\"], l[\"coin_symbol\"], l[\"x\"]],\n",
    "    condition=(l[\"Test name\"] == \"params_ftest\")\n",
    "    & (l[\"Significance simulation\"].isin(\"0.01\", \"0.1\")),\n",
    ").reset_index()\n",
    "features_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for alpha in features_metrics[\"Significance simulation\"].unique():\n",
    "    print(\"************************************************************\")\n",
    "    print(f\"Forecasting at Granger Causality Test at significant level {alpha}\")\n",
    "    f = features_metrics.loc[features_metrics[\"Significance simulation\"] == alpha]\n",
    "    feature_forecast(f\"forecast ({alpha})\", f, transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\"Total accuracy score over the number of forecasts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.visualize(\n",
    "    \"Features used in forecasting cryptocurrencies with more than 50% accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.url + \"/#/dashboard/332\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
